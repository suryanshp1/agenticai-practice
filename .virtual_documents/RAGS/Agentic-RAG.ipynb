import os
from dotenv import load_dotenv
load_dotenv()

from langchain_groq import ChatGroq
from langchain_openai import ChatOpenAI

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["GROQ_API_KEY"] = os.getenv("GROQ_API_KEY")


from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

urls = [
    "https://www.wikipedia.org/wiki/Deep_learning",
    "https://www.wikipedia.org/wiki/Artificial_intelligence",
    "https://www.wikipedia.org/wiki/Machine_learning",
]

docs = [WebBaseLoader(url).load() for url in urls]
docs_list = [doc for sublist in docs for doc in sublist]

text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=50)
doc_splits = text_splitter.split_documents(docs_list)

# Add all these texts to  the vector store
vector_store = FAISS.from_documents(documents=doc_splits, embedding=OpenAIEmbeddings())

# Create a retriever from the vector store
retriever = vector_store.as_retriever()


retriever.invoke("What is deep learning?")


from langchain.tools.retriever import create_retriever_tool

retriever_tool = create_retriever_tool(
    retriever=retriever,
    name="WikipediaRetriever",
    description="Useful for retrieving information from Wikipedia articles about AI, ML, and DL.",
)


retriever_tool


tools = [retriever_tool]


from typing import Annotated, Sequence
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict
from langgraph.graph.message import add_messages

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]


def agent(state: AgentState) -> str:
    messages = state["messages"]
    model = ChatGroq(model="qwen-qwq-32b")
    model = model.bind_tools(tools)
    response = model.invoke(messages)
    return {"messages": [response]}


from typing import Annotated, Literal, Sequence
from typing_extensions import TypedDict
from langchain import hub
from langchain_core.messages import HumanMessage, BaseMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from pydantic import Field, BaseModel


class Grade(BaseModel):
    """Binary score for relevance check"""
    binary_score: str = Field(
        description="Relevance score 'yes' or 'no'"
    )


def grade_documents(state: AgentState) -> Literal["generate", "rewrite"]:
    print("---------------CHECK RELEVANCE----------------")

    # model
    model = ChatGroq(model="qwen-qwq-32b", streaming=True)

    # llm with tools and validation
    llm_with_tools = model.with_structured_output(Grade)

    # prompt
    prompt = PromptTemplate(
        input_variables=["messages"],
        template="Is the following information relevant to the question? Respond with 'yes' or 'no'.\n\n{messages}",
    )


from langgraph.graph import END, START, StateGraph
from langgraph.prebuilt import ToolNode
from langgraph.prebuilt import tools_condition

# Define a new graph
workflow = StateGraph(AgentState)

# Define the nodes we will cycle through
workflow.add_node("agent", agent)
retrieve = ToolNode([retriever_tool])
workflow.add_node("retrieve", retrieve)
workflow.add_node("rewrite", rewrite)
workflow.add_node("generate", generate)

# Call agent node to decide to retrieve or not
workflow.add_edge(START, "agent")

# Decide whether to retrieve
workflow.add_conditional_edges("agent", tools_condition, {"tools": "retrieve", END: END})
workflow.add_conditional_edges("retrieve", grade_documents)
workflow.add_edge("generate", END)
workflow.add_edge("rewrite", "agent")

# Compile
graph = workflow.compile()
