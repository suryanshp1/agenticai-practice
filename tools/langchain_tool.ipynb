{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd52661",
   "metadata": {},
   "source": [
    "### Tools on LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4848efe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e9144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatVertexAI(model=\"gemini-2.0-flash-001\")\n",
    "llm = ChatOpenAI()\n",
    "question = \"how old is the US president?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400bc48",
   "metadata": {},
   "source": [
    "Modern LLMs hide the need to construct a prompt from the user, you can define your tools as schemas instead and pass them as a separate argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"google_search\",\n",
    "        \"description\": \"Returns about common facts, fresh events and news from Google Search engine based on a query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"title\": \"search_query\",\n",
    "                    \"description\": \"The search query to be sent to Google Search.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "step1 = llm.invoke(question, tools=[search_tool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8836853",
   "metadata": {},
   "source": [
    "As we can see, now our outputs contains a special part called tool_calls - again, there's no need for us to parse the output any more, it's all done by an LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f0012a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_EQdNDckqQei4vVDahtEAgfky', 'function': {'arguments': '{\"query\":\"current age of the US president\"}', 'name': 'google_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 80, 'total_tokens': 99, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C3wg3OVvA7IOUco2MumHqfprfnYFx', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--53f51bed-2b07-4551-95f6-6771f85650fc-0', tool_calls=[{'name': 'google_search', 'args': {'query': 'current age of the US president'}, 'id': 'call_EQdNDckqQei4vVDahtEAgfky', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 19, 'total_tokens': 99, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8624a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'google_search', 'args': {'query': 'current age of the US president'}, 'id': 'call_EQdNDckqQei4vVDahtEAgfky', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(step1.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae1c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current US President, Donald Trump, is 78 years old. He was born on June 14, 1946.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "tool_result = ToolMessage(content=\"Donald Trump â€º Age 78 years June 14, 1946\\n\", tool_call_id=step1.tool_calls[0][\"id\"])\n",
    "step2 = llm.invoke(\n",
    "    [HumanMessage(content=question), step1, tool_result],\n",
    "    tools=[search_tool]\n",
    ")\n",
    "assert len(step2.tool_calls) == 0\n",
    "\n",
    "print(step2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c0d274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_pBerL40VtJ8YM2SY8ddmtpFv', 'function': {'arguments': '{\"query\":\"age of US president\"}', 'name': 'google_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 80, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C3wm3WxJNeuSQb7HF29niKTeKcKQy', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--147758d9-67ae-4d22-b720-b4a2daa645a9-0', tool_calls=[{'name': 'google_search', 'args': {'query': 'age of US president'}, 'id': 'call_pBerL40VtJ8YM2SY8ddmtpFv', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 17, 'total_tokens': 97, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = llm.bind(tools=[search_tool])\n",
    "llm_with_tools.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd191238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
